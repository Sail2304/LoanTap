{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report, \n",
    "    roc_auc_score, roc_curve, auc,\n",
    "    ConfusionMatrixDisplay, RocCurveDisplay,\n",
    "    precision_recall_curve,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data=pd.read_csv(\"D:\\\\LoanTap\\\\LoanTap\\\\artifacts\\\\data_ingestion\\\\LoanTap.csv\")\n",
    "df = data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic info about data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic stats \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check null values\n",
    "df.isna().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.5% missing values in mort_acc column. Let's treat it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDA and Feature engineering\n",
    "# separate numerical and categorical columns for univariate analysis\n",
    "\n",
    "numerical_columns = list(df.loc[:, df.dtypes!=object].columns)\n",
    "categorical_columns = list(df.loc[:, df.dtypes==object].columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_and_boxplot(df, columm):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.histplot(data=df, x=columm, kde=True)\n",
    "    plt.title(f\"Distribution of {columm}\")\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.boxplot(data=df, x=columm)\n",
    "    plt.title(f\"Boxplot of {columm}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_columns:\n",
    "    plot_histogram_and_boxplot(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Even though data type of mort_acc and pub_rec_bankrupties have numerical data type they are categorical features.\n",
    "## Let's append these columns to categorical data\n",
    "\n",
    "categorical_columns.extend(['mort_acc','pub_rec_bankruptcies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of categories in each featue\n",
    "for col in categorical_columns:\n",
    "    print(f\"{col}-->{df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['purpose'].unique())\n",
    "print(df['title'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose and Title have same data.\n",
    "Let's drop title column as it has more categories due possibly to manual typing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns=['term',\n",
    "                        'grade',\n",
    "                        'sub_grade',\n",
    "                        'emp_length',\n",
    "                        'home_ownership',\n",
    "                        'verification_status',\n",
    "                        'purpose',\n",
    "                        'initial_list_status',\n",
    "                        'application_type',\n",
    "                        'mort_acc',\n",
    "                        'pub_rec_bankruptcies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot univariate counts and count w.r.t target\n",
    "def plot_countplot(df, col, target):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.countplot(data=df, y=col,stat='percent')\n",
    "    plt.title(f\"count plot of {col}\")\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.countplot(data=df, y=col,hue=target,stat='percent')\n",
    "    plt.title(f\"count plot of {col} w.r.t {target} \")\n",
    "    plt.show()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    plot_countplot(df, col, 'loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bivariate analysis between numerical features and target\n",
    "def plot_kdeplot(df, col, target):\n",
    "    plt.figure(figsize=(10,3))\n",
    "    sns.kdeplot(data=df, x=col,hue=target)\n",
    "    plt.title(f\"kde plot of {col} w.r.t {target}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_columns:\n",
    "    plot_kdeplot(df,col,'loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Impute missing values in mor_acc\n",
    "df['mort_acc'] = df['mort_acc'].fillna(df.groupby('total_acc')['mort_acc'].transform('median'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emp_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop emp_title column and null values from remianing columns\n",
    "df=df.drop(columns=['emp_title'])\n",
    "df = df.dropna()\n",
    "df.isna().sum()/len(df)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zip_code'] = df.address.apply(lambda x: x[-5:])\n",
    "df['zip_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city_code']=df.address.apply(lambda x: x[-8:-6])\n",
    "df['city_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['address'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['issue_d', 'earliest_cr_line'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = list(df.loc[:, df.dtypes==object].columns)\n",
    "# check number of categories in each featue\n",
    "for col in categorical_columns:\n",
    "    print(f\"{col}-->{df[col].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    " \n",
    "for col in categorical_columns:\n",
    "    res=chi2_contingency(pd.crosstab(df[col],df['loan_status']).values)\n",
    "    print(f\"{col}: {res.pvalue}\")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove city_code column as it is having pvalu>0.05\n",
    "df = df.drop(columns=['city_code'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns.remove('city_code')\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['term']=df['term'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    print(f\"{col}--> {df[col].unique()}--> {df[col].nunique()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode grade and sub_grade using label encoder as these features are ordinal and remaining_features using one hot encoder\n",
    "label_encoder_grade=LabelEncoder()\n",
    "label_encoded_features=label_encoder_grade.fit_transform(df['grade'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_subgrade=LabelEncoder()\n",
    "label_encoded_subgrade=label_encoder_subgrade.fit_transform(df['sub_grade'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_emp_length=LabelEncoder()\n",
    "label_encoded_emp_length = le_emp_length.fit_transform(df['emp_length'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emp_length'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoder(drop=['36 months','RENT','Not Verified','vacation','w','INDIVIDUAL','22690'])\n",
    "ohe_encoded_features = ohe.fit_transform(df[['term','home_ownership','verification_status','purpose','initial_list_status','application_type','zip_code']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_encoded_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.inverse_transform(np.array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_data=pd.DataFrame(ohe_encoded_features, columns=ohe.get_feature_names_out())\n",
    "ohe_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_data=pd.DataFrame({'le_grade':label_encoded_features.reshape(-1,), \n",
    "                      'le_subgrade':label_encoded_subgrade.reshape(-1,),\n",
    "                      'le_emp_length':label_encoded_emp_length.reshape(-1,)})\n",
    "le_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "final_data = pd.concat([df,ohe_data, le_data], axis=1)\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= final_data.drop(columns=categorical_columns)\n",
    "y = final_data[['loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['loan_status']=y['loan_status'].apply(lambda x: 1 if x=='Charged Off' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train_scaled=sc.fit_transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled=sc.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lr.predict(x_test_scaled)\n",
    "acc=accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
